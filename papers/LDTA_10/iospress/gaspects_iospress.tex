% PLEASE USE THIS FILE AS A TEMPLATE FOR THE PUBLICATION 
% Check file IOS-Book-Article.tex
%

\documentclass{IOS-Book-Article}     %[seceqn,secfloat,secthm]
%\usepackage[T1]{fontenc}
%\usepackage{times}%
\normalfont%
%\usepackage[mtplusscr,mtbold]{mathtime}%
%\usepackage{authblk}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage{soul}
\usepackage{color}
\usepackage{bold-extra}
\usepackage{url}
%\newcommand{\linkcolor}{blue}
\newcommand{\linkcolor}{black}
\usepackage[
	colorlinks=true,
	linkcolor=\linkcolor,
	citecolor=\linkcolor,
	urlcolor=\linkcolor
]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%% Put your definitions here
\definecolor{Brown}{cmyk}{0,0.81,1,0.60}
\definecolor{OliveGreen}{cmyk}{0.64,0,0.95,0.40}
\definecolor{CadetBlue}{cmyk}{0.62,0.57,0.23,0}
\definecolor{StringBlue}{rgb}{0,0,1}
%\definecolor{Brown}{rgb}{0,0,0}
%\definecolor{OliveGreen}{rgb}{0,0,0}
%\definecolor{CadetBlue}{rgb}{0,0,0}
%\definecolor{StringBlue}{rgb}{0,0,0}
\renewcommand{\ttdefault}{pcr}

\newcommand{\bad}[1]{\textcolor{red}{#1}}
\renewcommand{\bad}[1]{#1}
\sloppy
%\newcommand{\note}[1]{\noindent \begin{tabular}{|c|}\hline \textcolor{blue}{#1}\\ \hline \end{tabular}}
\newcommand{\comment}[1]{}

\newcommand{\abstr}[3]{\lambda \, #1 \approx #2 \,.\, #3}
\newcommand{\sem}[1]{[\![#1]\!]}
\newcommand{\fresh}[1]{#1^\dagger}
\newcommand{\Eq}{\mathcal{S}}
\newtheorem{Def}{Definition}

\newcommand{\fig}[2]{%
\begin{figure}%
\centering%
\includegraphics[width=\textwidth]{#1}%
\caption{#2}\label{#1}%
\end{figure}%
}

\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\lstref}[1]{Listing~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}

\newcommand{\tool}[1]{\textsc{#1}}
\newcommand{\Grammatic}[0]{\tool{Grammatic}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% Pseudocode
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\itemsepdelta}{%
%	\setlength{\itemsep}{0pt}%
%	\setlength{\topsep}{0pt}%
%	\setlength{\partopsep}{0pt}%
}%
\newcommand{\subroutine}[3]%name inputs, body
{\textsc{#1} (#2) \textbf{is}%
\begin{itemize}%
	\itemsepdelta%
	#3 %
\end{itemize}}%
%
\newcommand{\statement}[1]{\item #1}%
%
\newcommand{\var}[1]{\texttt{#1}}%
%
\newcommand{\foreach}[3]% what where body
{\item \textbf{for each} \var{#1} \textbf{in} \var{#2} %
\begin{itemize}%
	\itemsepdelta%
	#3%
\end{itemize}}%
\newcommand{\ifst}[3]%if then else
{\item \textbf{if} #1 %
\begin{itemize}%
	#2%
\end{itemize}%
}%
%
\newcommand{\call}[2]%
{\item \textbf{call} \textsc{#1}(#2)}%


%%%%%%%%%%% End of definitions
\begin{document}
\begin{frontmatter}          % The preamble begins here.
%
%\pretitle{}
\title{Grammatical Aspects: Coping with Duplication and Tangling in Language Specifications\thanks{This work was partly done while the author was a visiting PhD student at University of Tartu, under a scholarship from European Regional Development Funds through Archimedes Foundation. Author would like to acknowledge the advice received from Professor Marlon Dumas.}}
\runningtitle{Grammatical Aspects: Coping with Grammar Duplication and Tangling}
%\subtitle{}

% For one author:
\author{\fnms{Andrey} \snm{Breslav}}
\address{ITMO University, Saint-Petersburg, Russia}
\runningauthor{A. Breslav}
%
\begin{abstract}
	For the purposes of tool development, computer languages are usually described using context-free grammars with annotations such as semantic actions or pretty-printing instructions. 
	These specifications are processed by generators which automatically build software, e.g., parsers, pretty-printers and editing support.

	In many cases the annotations make grammars unreadable, and when generating code for several tools supporting the same language, one usually needs to duplicate the grammar in order to provide different annotations for different generators.

	We present an approach to describing languages which improves readability of grammars and reduces the duplication. To achieve this we use Aspect-Oriented Programming principles. This approach has been implemented in an open-source tool named \Grammatic{}. We show how it can be used to generate pretty-printers and syntax highlighters.
\end{abstract}

\begin{keyword}
DSL, Grammar, Aspect
\end{keyword}

\end{frontmatter}

%%%%%%%%%%% The article body starts:
\section*{Introduction}

\lstset{
  showspaces=false,
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\bfseries\color{Brown},
  commentstyle=\color{OliveGreen},
  stringstyle=\color{StringBlue},
  tabsize=4,
  captionpos=b,
  showstringspaces=false,
  aboveskip=.5\smallskipamount,
  belowskip=.5\smallskipamount
}
\lstdefinelanguage{Grammatic}
	{
		morestring=[b]',
		morekeywords={lex,empty,*,?,+},
		morecomment=[l]{//},
	}

% State-of-the-art
With the growing popularity of Domain-Specific Languages, the following types of supporting tools are created \bad{more and} more frequently:
%%\bad{We need to support many features for a single language nowadays. Which is inevitable with presence of DSLs.}
%% The automation of the following \bad{problems} has been studied by programming language researchers for many years:
\begin{itemize}
	\item Parsers and translators;
	\item Pretty-printers;
	\item Integrated Development Environment (IDE) add-ons for syntax highlighting, code folding and outline views.
\end{itemize}
Nowadays these types of tools are usually developed with the help of generators which accept language specifications in the form of annotated (context-free) grammars. 

% Downsides of the existing solutions
For example, tools such as \tool{YACC} \cite{YACC} and \tool{ANTLR} \cite{ANTLR} use grammars annotated with embedded semantic actions. As an illustration of this approach first consider an annotation-free grammar for arithmetic expressions (\lstref{arithexpr}).
\begin{lstlisting}[language=Grammatic,label=arithexpr,caption=Grammar for arithmetic expressions,float]
    expr : term ((PLUS | MINUS) term)* ;
    term : factor ((MULT | DIV) factor)* ;
    factor : INT | '(' expr ')' ;
\end{lstlisting}
To generate a translator, one has to annotate the grammar rules with embedded semantic actions. \lstref{annotated_rule} shows the rule \texttt{expr} from \lstref{arithexpr} annotated for \tool{ANTLR} v3.
\begin{lstlisting}[caption=Annotated grammar rule,label=annotated_rule,float]
    expr returns [int result] : 
        t=term {result = t;} 
        ({int sign = 1;} (PLUS | MINUS {sign = -1;}) 
                               t=term {result += sign * t;})*;
\end{lstlisting}

As can be seen, the context-free grammar rule is not easily readable in \lstref{annotated_rule} because of the actions' code interfering with the grammar notation. This problem is common for annotated grammars. We will refer to it as \emph{tangled grammars}.

\fig{problems_and_solution}{Generating two supporting tools for the same language}
In most applications we need to create several supporting tools for the same language (see \figref{problems_and_solution}, left side). 
In such a case one uses different generators to obtain different programs (e.g., \tool{Pretzel} \cite{Pretzel} to build a pretty-printer and \tool{xText} \cite{Xtext} to create an Eclipse editor). Each generator requires its own specific set of annotations, and the developer has to write the same grammar several times with different annotations for each generator. Besides the duplication of effort, when the language evolves, this may lead to inconsistent changes in different copies of the grammar, which may cause issues which are hard to detect. We will refer to this problem as \emph{grammar duplication}.

% Our aims
This paper aims at reducing tangling and duplication in annotated grammars. 
% General means of the solution
A high-level view of our approach is illustrated in \figref{problems_and_solution}~(right side): the main idea is to separate the annotations from the grammar by employing the principles similar to those behind the AspectJ language \cite{AspectJ}, this leads to a notion of a \emph{grammatical aspect}. Our approach is implemented in an open-source tool named \Grammatic{}\footnote{The tool is available at \url{http://grammatic.googlecode.com}}. 
%In this paper we show how \Grammatic{} is used to generate a syntax highlighter and a pretty-printer on the basis of a common context-free grammar.

% Paper structure
In \secref{Background} we briefly describe the main notions of aspect-oriented programming in AspectJ. 
Definitions related to grammatical aspects and their formal semantics are given in \secref{Approach}. 
\secref{Example} studies the applications of \Grammatic{} to generating syntax highlighters and pretty-printers on the basis of a common grammar. We analyze these applications and evaluate our approach in \secref{Discussion}. Related work is described in \secref{Related}. \secref{Conclusion} summarises the contribution of the paper and introduces possible directions of the future work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}\label{Background}
Aspect-Oriented Programming (AOP) is a body of techniques aimed at increasing modularity in general-purpose programming languages by separating cross-cutting concerns. Our approach is inspired by AspectJ \cite{AspectJ}, an aspect-oriented extension of Java. 

AspectJ allows a developer to extract the functionality that is scattered across different classes into modules called \emph{aspects}. At compilation- or run-time this functionality is \emph{weaved} back into the system. The places where code can be added are called \emph{join points}. Typical examples of join points are a method entry point, an assignment to a field, a method call. 

AspectJ uses \emph{pointcuts} --- special constructs that describe collections of join points to weave the same piece of code into many places. Pointcuts describe method and field signatures using patterns for names and types. For example, the following pointcut captures \textit{calls of all public \texttt{get-}methods in the subclasses of the class \texttt{Example} which return \texttt{int} and have no arguments}:
\begin{lstlisting}[language={[AspectJ]Java}]
    pointcut getter() : call(public int Example+.get*())
\end{lstlisting}

The code snippets attached to a pointcut are called \emph{advice}; they are weaved into every join point that matches the pointcut. For instance, the following advice writes a log record after every join point matched by the pointcut above:
\begin{lstlisting}[language={[AspectJ]Java}]
    after() : getter() {
        Log.write("A get method called");
    }
\end{lstlisting}
In this example the pointcut is designated by its name, \texttt{getter}, that follows the keyword \texttt{after} which denotes the position for the code to be weaved into.
An \emph{aspect} is basically a unit comprising of a number of such pointcut-advice pairs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overview of the approach}\label{Approach}

Out approach employs the principles of AOP in order to tackle the problems of tangling and duplication in annotated grammars. We will use the grammar from \lstref{arithexpr} and the annotated rule from \lstref{annotated_rule} to illustrate how the terms such as ``pointcut'' and ``advice'' are embodied for annotated grammars. 

% Join points
\subsection{Grammatical join points}
\figref{structured} shows a structured representation (a syntax diagram) of the annotated rule from \lstref{annotated_rule}. 
\fig{structured}{Annotations attached to a grammar rule}
It shows the annotations attached to a symbol definition \texttt{expr}, three symbol references: \texttt{term} (two times) and \texttt{MINUS}, and an alternative~\mbox{\texttt{(PLUS | MINUS)}} (marked ``\emph{alt}'' in the figure). All these are examples of \emph{grammatical join points} (in \figref{structured} they are marked with black circles). 

Below we use \tool{ANTLR}'s notation for context-free grammars and reflect on ASTs of this notation. To avoid confusion with ASTs of languages defined by the grammar, we will refer to the AST of the grammar itself as \emph{grammar tree} (GT). The language of GTs is given by the following type definitions:
\begin{lstlisting}[language=Haskell]
data Grammar = Grammar {rules :: Set(Rule)}
data Rule = Rule {name :: String, body :: Expression}
data Expr -- Expressions
	= SymRef {name :: String}  -- Symbol reference
	| Literal {value :: String} | Empty
	| Seq {exprs :: List(Expr)} -- Sequence
	| Alt {exprs :: Set(Expr)}  -- Alternative
	| Iter {exprs :: Expr, multiplicity :: Mult}  -- Iteration
data Mult = Star | Plus | Option
\end{lstlisting}
Every node in a GT can be a join point, thus we have as many join point types as data constructors in the GT language above.

% Pointcuts
\subsection{Grammatical pointcuts}

Pointcuts are expressions denoting sets of join points, i.e. \emph{patterns} over the GT language. The language of pointcuts is obtained from the GT language by adding special constructs, namely wildcards and variable bindings (see \tabref{wildcards}).
%
\begin{table}[h!]
\centering
\begin{tabular}{|@{}c|l|}
	\hline
	\bf Notation & \bf Matches any\ldots \\
	\hline
	?\emph{Type} & Any instance of type \emph{Type} \\
	? & Any symbol (?SymRef)\\
	?lex & Any lexical literal (?Literal) \\
	{}[?]& Any sequence \\
	\{?\}& Any set of alternatives \\
	$\;\abstr{var}{expr_1}{expr_2(var)}$ & Variable binding \\
	\hline
\end{tabular}
\caption{Notions introduced in the pointcut language (in addition to the GT nodes)}\label{wildcards}
\end{table}
%
Consider some examples of patterns for the rules from \lstref{arithexpr}:
\begin{itemize}
	\item[(a)] \lstinline!expr : [?]! --- a rule defining a symbol ``expr'' with an arbitrary expression on the right-hand side (in \lstref{arithexpr} it matches only the rule for \texttt{expr});
	\item[(b)] \lstinline!? : term [?]! --- a rule for any symbol, starting with a reference to a symbol named ``term'' (also matches only the rule for \texttt{expr});
	\item[(c)] \lstinline!? : ? [?]*! --- a symbol reference followed by a star iterating an arbitrary sequence (matches the rules for \texttt{expr} and \texttt{term}).
\end{itemize}
Note that constructors of the GT language are used in patterns (typing is relaxed). Here is the example (b) from above written in the abstract syntax (``$:$'' denotes the \emph{cons} operation on lists):
 $Rule(?SymRef, Seq(SymRef(\mbox{``term''})\,:\,?List(Expr)))$.

Variables are used to label a subexpression and refer to it later. In the abstract syntax this can be written, for example, as\\
\indent
$
\abstr{tr}{?SymRef}{tr\;((\mathtt{PLUS} \,|\, \mathtt{MINUS})\; tr)^*}
$\\
Here the variable \texttt{tr} is defined with the pattern $?SymRef$ (any symbol) which means that all usages of the variable will match only occurrences of the same symbol. This pattern matches the rule for \texttt{expr} because the same symbol \texttt{term} is referenced in the positions matched by the variable \texttt{tr}. In concrete syntax variables are defined inside the pattern, and prefixed by a dollar sign so that the pattern given above is written as follows:\\
\indent\lstinline!? : $tr=? ((PLUS | MINUS) $tr)*!

In this paper we assume that GT nodes are \emph{not} shared, and subtrees of the same shape occurring at different positions are distinct. This corresponds to having unique numbers implicitly assigned to nodes, below we refer to this numbers as \emph{identity labeling} and write $\mathcal{IL}(n)$ for the identity-label of a node $n$. In this regard, note that a variable is in general bound to a \emph{set} of GT nodes: if we match the rule for \texttt{expr} against the pattern in the example above, the variable \texttt{tr} will be bound to a set comprised by two distinct references to \texttt{term}.

% Advice
\subsection{Grammatical advice}
Annotations attached to grammars (they are analogous to AspectJ's \emph{advice}) may have an arbitrarily complicated structure: in general, a generator may need a very rich annotation system. We use a \emph{generic annotation language}, which represents the annotations as sets of name-value pairs which we call \emph{attributes}. Examples of such pairs are given in \tabref{value_types} which shows all the predefined value types. Values may also have user-defined types which can be plugged in. The annotations in \figref{structured} may be represented, for example, as values of type String (other representations are also possible).

\begin{table}[h!]
\centering
\begin{tabular}{|r@{\tt{}\,=\,}l@{\tt}|l|}
	\hline
	\multicolumn{2}{|c|}{\bf Example} & \bf Value type \\
	\hline
	int&10 & Integer \\
	str&'Hello' & String \\
	id&SomeName & Name literal\\
	rec&\{b = c; d = 5\}\, & Annotation\\
	seq&[1, a b 'str'] \,& Sequence of values \\
	\hline
\end{tabular}
\caption{Predefined value types}\label{value_types}
\end{table}

As the usage of the term ``attribute'' may be misleading in this context, we would like to note that the approach presented here does not directly correspond to attribute grammars \cite{ATG}. In fact, grammars with annotations do not have any particular execution semantics (each generator interprets the annotations in its own way), as opposed to attribute grammars which have a fixed execution semantics. One can describe attribute grammars using our approach and define corresponding semantics in a generator, but this is just an example application.

% Aspects
\subsection{Grammatical aspects}
Now, having described all the components, we can assemble a \emph{grammatical aspect} as a set of pointcut-advice pairs.
Usage of grammatical aspects is illustrated by \figref{problems_and_solution}.

An aspect consists of an optional \emph{grammar annotation} and zero or more \emph{annotation rules}. Annotation rules associate grammatical pointcuts (rule patterns) with advice (annotations). Here is an example of an annotation rule:
\begin{lstlisting}[language=Grammatic]
expr : $tr=? ([?] $tr)*    // pointcut (pattern)
    $tr {varName = 't'} ;  // advice (annotation)
\end{lstlisting}%$
In a simple case exemplified here, an annotation \lstinline!{varName = 't'}! is attached to GT nodes to which a variable \texttt{tr} is bound.
For more complicated cases, one can define arbitrarily nested \emph{subpatterns} --- patterns being matched against nodes situated in a particular GT subtree. For example, the following construct attaches an attribute named \texttt{varName} to each reference to the symbol \texttt{term} \emph{inside a rule matched by a top-level pattern}:
\begin{lstlisting}[language=Grammatic]
expr : [?]                   // pointuct (pattern) 
    @$tr=(term):             // pointcut (subpattern)
       $tr {varName = 't'} ; // advice (annotation)
\end{lstlisting}
This example illustrates the typical usage of subpatterns where all annotations are associated with a variable bound to the whole pattern. As a shorthand for this situation the variable can be omitted (it will be created implicitly). Using this shorthand we can abridge the previous example to the following:
\begin{lstlisting}[language=Grammatic]
expr : [?]
    @term: { varName = 't' } ; 
\end{lstlisting}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Semantics of pointcuts and aspects}

To precisely define what happens when an aspect is applied to a language specification, in this section we give formal semantics to the constructs described above. The key point in this formalization is to characterize pointcut matching by establishing a system of inequalities over sets of terms\footnote{Since terms are trees, in this section we use ``GT node'' and ``term'' interchangeably.} corresponding to pointcuts. Solutions of these inequalities give valuations to variables defined inside patterns and subpatterns.

\begin{Def}[System of set inequalities]
Given an infinite set of variables $\mathcal{V}$, finite set of types $\mathcal{T}$ and value constructors $\mathcal{C}$ (we denote the set of all possible constructor applications as $\overline{\mathcal{C}}$),
a \emph{system of set inequalities} is a finite set of expressions of the following forms:
\begin{itemize}
\item $x \in S$, where $x \in \mathcal{V} \cup \overline{\mathcal{C}}$, 
\item or $S_1 = S_2$, where $S_i \in \mathcal{V} \cup \overline{\mathcal{C}}$ or $S_i \subseteq \overline{\mathcal{C}}$.
\end{itemize}
Given such a system $S$, a function $\sigma : \mathcal{V}  \rightarrow \overline{\mathcal{C}}$ is called a \emph{solution} of $S$, iff replacing every occurrence of every $v \in \mathcal{V}$ in $S$ by $\sigma(v)$ turns all the entries of $S$ into true statements.
\end{Def}
In addition to the common set operations, we use the following conventions:
\begin{itemize}
	\item $\sem{T}$, where $T \in \mathcal{T}$ denotes a set of all values of type $T$.
	\item If $C \in \mathcal{C}$, then $C(S_1, \ldots, S_n) = \{C(s_1, \ldots, s_n) \,|\, s_1 \in S_1, \ldots, s_n \in S_n\}$.
	\item For $t \in \overline{\mathcal{C}}$, $Subterms(t)$ is the set of all direct and indirect subterms of $t$ (identity-labeled).
	\item $L_1 \oplus L_2 = \{l_1 \oplus l_2 \,|\, l_1 \in L_1, l_2 \in L_2\}$, where $\oplus$ denotes list concatenation.
	\item A single value can be treated as a singleton set or singleton list containing this value, if required by the context.
\end{itemize}

\figref{Eq} defines a function $\Eq{}$ that takes a variable and a pattern as arguments and returns a system of set inequalities. We denote variables $v$ which are supposed to be fresh with respect to the rest of the system as $\fresh{v}$. 
\begin{Def}[Matching, Root variable]\label{SPT}
Given a pointcut expression $P$ and a GT $t$, let 
$$S_P(t) = \Eq{}(\fresh{R}, P) \cup \{R = t\}$$
$R$ is called the \emph{root variable}. Then, $P$ \emph{matches} $t$ iff there is a solution $\sigma$ to $S_P(t)$.
\end{Def}

\begin{figure}%
\centering%
$
\begin{array}{rcl}
\Eq(V, \mathbf{Type}(t_1, \ldots, t_n)) &=& \{V \in \mathbf{Type}(\fresh{v_1}, \ldots, \fresh{v_n})\} \cup 
\bigcup_1^n \Eq{}(v_i, t_i),\\
\mbox{where } \mathbf{Type} &\in& \{
	\mathtt{Grammar}, \mathtt{Rule}, \mathtt{Iter}, \mathtt{SymRef}, \mathtt{Literal}, \mathtt{Empty}\}\\

\Eq{}(V, ?Type) &=& \{V \in \sem{Type}\}\\

\Eq{}(V, \abstr{v}{e_1}{e_2}) &=& \Eq{}(v, e_1) \cup \Eq{}(V, e_2)\\

\Eq{}(V, Seq(e_1, \ldots, e_n)) &=& \{V \in Seq(\fresh{L})\} \cup \{ L = \fresh{L_1} \oplus \ldots \oplus \fresh{L_n}\} \cup \bigcup_1^n \Eq{}(L_i, e_i)\\

\Eq{}(V, [?]) &=& \{ V \in \sem{List(Expr)} \}\\

\Eq{}(V, Alt(e_1, \ldots, e_n, \{?\})) &=& \{V \in Alt(\fresh{S})\}
                                   \cup \bigcup_1^n \Eq{}(\fresh{t_i}, e_i) \cup \\
                               &&    
                                   \cup \bigcup_1^n \{ t_i \in S\}
                                   \cup \{ \fresh{R} = S \setminus
                                                          \bigcup_1^n\{t_i\}\}\\
\Eq{}(V, v) &=& \{V = v\}
\end{array}
$
\caption{Transforming a pattern into a system of inequalities}\label{Eq}%
\end{figure}%

To incorporate a subpattern $P_1$ into this definition, it is enough to consider an extended system $S_{P, P_1}(t) = S_P(t) \cup S_{P_1}(t) \cup \{R_1 \in Subterms(R)\}$, where $R$ is the root variable for $S_P(t)$, and $R_1$ is the root variable for $S_{P_1}(t)$. Arbitrarily nesting subpatterns are easily expressible in this manner.

According to these definitions, if $P$ matches $t$, then if we substitute all variables in $S_P(t)$ by their values given by $\sigma$, all the entries in the system turn into true statements. This gives a precise definition of matching, but does not yet define what values are bound to variables defined in $P$ (we refer to the set of such variables as $\mathcal{V}_P$). Note that according to \figref{Eq}, every $v \in \mathcal{V}_P$ appears in $S_P(t)$, and thus, $\sigma(v)$ seems to be a good candidate, but it is not: it only gives a term \emph{structurally equivalent} to all values bound by $v$, but not the set of actual identity labels for particular subterms. However, this set can be reconstructed during the substitution of $\sigma(v)$ into $S_P(t)$: whenever we substitute a term for $v \in \mathcal{V}_P$, we label this term with $v$ (a single term may be labeled by many variables). In the end, we substitute a term $t'$ for the root variable $R$, and it is structurally equivalent to $t$ as stated by the Definition \ref{SPT}. Given the identity labels in $t$ and variable labels in $t'$, we can derive a function called \emph{$\sigma$-labeling} of $t$:
$$\mathcal{L}_\sigma : \mathcal{IL}(Subterms(t)) \rightarrow 2^{\mathcal{V}},$$
where $\mathcal{L}_\sigma(n)$ is the labeling of the corresponding term in $t'$. Using this function, we can define the set of variables bounded to a variable $v$:
\begin{Def}[Bounding function]
A function $\mathcal{B}_\sigma : \mathcal{V}_P \rightarrow 2^{\mathcal{IL}(Subterms(t))}$, such that $$\mathcal{B}_\sigma(v) = \{n \,|\, v \in \mathcal{L}_\sigma(n)\},$$
is called a \emph{bounding function} for $S_P(t)$.
\end{Def}

To complete the semantics of aspects, note that an aspect rule $r$ gives a function $V_r(v)$ returning an annotation to be associated to every $n \in \mathcal{B}_\sigma(v)$. To apply a particular rule $r$ (a pointcut $P_r$ and the annotation function $V_r$), for every node $t$ in the GT, if there is a solution $\sigma$ for $S_{P_r}(t)$, then for every $v \in \mathcal{V}_{P_r}$ associate $V_r(v)$ with every $n \in \mathcal{B}_\sigma(v)$. If there are two annotations associated to the same node, they are merged (duplicate attributes, if any, are kept). Naturally, the grammar annotation (if present) is simply associated to the whole grammar.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Implementation}
Our approach is implemented as an open-source tool \Grammatic{}\footnote{The tool is available at \url{http://grammatic.googlecode.com}} written in Java. The tool provides concrete syntax for grammar specifications and aspects and implements the matching and application semantics given above. 

\Grammatic{} works as a front-end to generators that use its API. First, it takes a specification and applies aspects. If the application was successful, the resulting structure (GT nodes with attached annotations) is passed to the generator which processes it as a whole and needs no information about aspects. To use a pre-existing tool, for example, \tool{ANTLR}, with grammatical aspects, one can employ a small generator which calls \Grammatic{} to apply aspects to grammars, and produces annotated grammars in the ANTLR format.

From the practical point of view, it is important that the definitions in the previous section allow a single join point to match more than once. Depending on the grammar, this behavior may be intended by the developer, or not. To provide some means of control over this behavior, patterns and subpatterns may be preceded by a \emph{multiplicity directive}. For example:
\begin{lstlisting}[language=Grammatic]
(0..1) ? : $tr=? ([?] $tr)* // pointcut with multiplicity
    // some advice
\end{lstlisting}
A multiplicity directive determines a number of times the pattern is allowed to match. The default multiplicity is \texttt{(1..*)} which means that each pattern with no explicit multiplicity is allowed to match one or more times. When an aspect is applied to a grammar, if the actual number of matches goes beyond the range allowed by a multiplicity directive, an error message will be generated. In the example above, there will be an error when matching against the grammar from \lstref{arithexpr} because the pattern matches two rules: \texttt{expr} and \texttt{term}, which violates the specified multiplicity \texttt{(0..1)}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Applications}\label{Example}
In this section we show how one can make use of grammatical aspects when generating syntax highlighters and pretty-printers on the basis of the same grammar.
\subsection{Specifying syntax highlighters}

A syntax highlighter generator creates a highlighting add-on for an IDE, such as a script for \texttt{vim} editor or a plug-in for Eclipse. For all targets the same specification language is used: we annotate a grammar with \emph{highlighting groups} which are assigned to occurrences of terminals. Each group may have its own color attributes when displayed. Common examples of highlighting groups are \emph{keyword}, \emph{number}, \emph{punctuation}. 

In many cases syntax highlighters use only lexical analysis, but it is also possible to employ light-weight parsers \cite{Island}. In such a case grammatical information is essential for a definition of the highlighter. Below we develop an aspect for the Java grammar which defines groups for keywords and for \emph{declaring occurrences} of class names and type parameters. A declaring occurrence is the first occurrence of a name in the program; all the following occurrences of that name are \emph{references}. Consider the following example:

\lstset{language=Java}
\lstinline!class!\texttt{ \ul{Example}<\ul{A}, \ul{B} }\lstinline!extends!\texttt{ A> }\lstinline!implements!\texttt{ Some<\ul{?}} \lstinline!super!\texttt{ B>} 

This illustrates how the generated syntax highlighter should work: the declaring occurrences are underlined (occurrences of \texttt{?} are always declaring) and the keywords are shown in bold. This kind of highlighting is helpful especially while developing complicated generic signatures.

\lstref{java} shows a fragment of the Java grammar \cite{JLS} which describes class declarations and type parameters. In \lstref{java_aspect} we provide a grammatical aspect which defines three highlighting groups: \emph{keyword}, \emph{classDeclaration} and \emph{typeParameterDeclaration}, for join points inside these rules.

\begin{lstlisting}[language=Grammatic,caption=Class declaration syntax in Java 5,label=java,float]
normalClassDeclaration
	: 'class' IDENTIFIER typeParameters? 
           ('extends' type)? ('implements' typeList)? classBody ;
classBody
	: '{' classBodyDeclaration* '}' ;
typeParameters
	: '<' typeParameter (',' typeParameter)* '>' ;
typeParameter
	: IDENTIFIER ('extends' bound)? ;
bound
	: type ('&' type)* ;
type
	: IDENTIFIER typeArgs? ('.' IDENTIFIER typeArgs?)* ('[' ']')*
	: basicType ;
typeArgs
	: '<' typeArgument (',' typeArgument)* '>' ;
typeArgument
	: type
	: '?' (('extends' | 'super') type)? ;
\end{lstlisting}

\lstset{language=Grammatic}
Each annotation rule from \lstref{java_aspect} contains two subpatterns. The first one is \texttt{?lex}: it matches every lexical literal. For example, for the first rule it matches \texttt{'class'}, \texttt{'extends'} and \texttt{'implements'}; the highlighting group \texttt{keyword} is assigned to all these literals.

The second subpattern in each annotation rule is used to set a corresponding highlighting group for a declaring occurrence: for classes and type parameters it matches \texttt{IDENTIFIER} and for wildcards --- the \texttt{'?'} literal.

When the aspect is applied to the grammar, \Grammatic{} attaches the \texttt{group} attribute to the GT nodes matched by the patterns in the aspect. The obtained annotated grammar is processed by a generator which produces code for a highlighter.

\begin{lstlisting}[language=Grammatic,caption=Highlighting aspect for class declarations in Java,float,label=java_aspect]
? : 'class' IDENTIFIER [?]
	@?lex: { group = keyword } ;
	@IDENTIFIER: { group = classDeclaration } ;
typeParameter : IDENTIFIER [?]
	@?lex: { group = keyword } ;
	@IDENTIFIER: { group = typeParameterDeclaration } ;
typeArgument : [?]
	@?lex: { group = keyword } ;
	@'?': { group = typeParameterDeclaration } ;
\end{lstlisting}

% Pretty-printers
\subsection{Specifying pretty-printers}

By applying a different aspect to the same grammar (\lstref{java}), one can specify a pretty-printer for Java. A pretty-printer generator relies on annotations describing how tokens should be aligned by inserting whitespace between them. 

In \lstref{pp_aspect} these annotations are given in the form of attributes \texttt{before} and \texttt{after}, which specify whitespace to be inserted into corresponding positions. Values of the attributes are \emph{sequences} (\texttt{[...]}) of strings and name literals \texttt{increaseIndent} and \texttt{decreaseIndent} which control the current level of indentation. 

The most widely used values of \texttt{before} and \texttt{after} are specified in a \emph{grammar annotation} by attributes \texttt{defaultBefore} and \texttt{defaultAfter} respectively, and not specified for each token individually. In \lstref{pp_aspect} the default formatting puts nothing before each token and a space --- after each token; it applies whenever no value was set explicitly.

\begin{lstlisting}[language=Grammatic,caption=Pretty-printing aspect for class declarations in Java,label=pp_aspect,float]
{ // Grammar annotation
	defaultAfter = [ ' ' ]; 
	defaultBefore = [ '' ];
} 
	
classBody : '{' classBodyDeclaration* '}'
	@'{': { after = [ '\n' increaseIndent ] } ;
	@classBodyDeclaration: { after = [ '\n' ] } ;
	@'}': {
		before = [ decreaseIndent '\n' ];
		after = [ '\n' ];
	};
typeParameters : '<' typeParameter (',' typeParameter)* '>' 
	@'<': { after = [ '' ] } ;
	@typeParameter: { after = [ '' ] } ;
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}\label{Discussion}

This paper aims at coping with two problems: tangled grammars and grammar duplication. 
When using \Grammatic{}, a single annotated grammar is replaced by a \emph{pure} context-free grammar and a set of grammatical aspects. This means that the problem of \emph{tangled grammars} is successfully addressed.

This also means that the grammar is written down only once even when several aspects are applied (see the previous section). But if we look at the aspects, we see that the patterns carry on some extracts from the grammar thus it is not so obvious whether our approach helps against the problem of \emph{duplication} or not. Let us examine this in more details using the examples from the previous section.

From the perspective of grammar duplication, the worst case is an aspect where all the patterns are exact citations from the grammar (no wildcards are used, see \lstref{pp_aspect}). This means that a large part of the grammar is completely duplicated by those patterns. But if we compare this with the case of conventional annotated grammars, there still is at least one advantage of using \Grammatic{}. Consider the scenario when the grammar has to be changed. In case of conventional annotated grammars, the same changes must be performed once for each instance of the grammar and there is a risk of inconsistent changes which are not reported to the user. In \Grammatic{}, on the other hand, a developer can control this using \emph{multiplicities}: for example, check if the patterns do not match anything in the grammar and report it (since the default multiplicities require each pattern to match at least once, this will be done automatically). Thus, even in the worst case, grammatical aspects make development less error-prone.

%With abstract aspects, it's likely that one won't need to change the patterns at all
Using wildcards and subpatterns as it is done in \lstref{java_aspect} (i) reduces the duplication and (ii) makes a good chance that the patterns will not need to be changed when the grammar changes. For example, consider the first annotation rule from \lstref{java_aspect}: this rule works properly for both Java version~1.4 and version~5 (see \lstref{java_14} and \lstref{java} respectively). The pointcut used in this rule is sustainable against renaming the symbol on the left-hand side (\texttt{classDeclaration} was renamed to \texttt{normalClassDeclaration}) and structural changes to the right-hand side (type parameters were introduced in Java~5). The only requirement is that the definition should start with the \texttt{'class'} keyword followed by the \texttt{IDENTIFIER}.

\begin{lstlisting}[language=Grammatic,caption=Class declaration rule in Java 1.4,label=java_14,float]
classDeclaration
	: 'class' IDENTIFIER ('extends' type)? 
                         ('implements' typeList)? classBody ;
\end{lstlisting}

In AOP, the duplication of effort needed to modify pointcuts when the main program changes is referred to as the \emph{fragile pointcut problem} \cite{Fragile}. Wildcards and subpatterns make pointcuts more \emph{abstract}, in other words, they widen the range of join points matched by the pointcuts. From this point of view, wildcards help to abstract over the contents of the rule, and subpatterns --- over the positions of particular elements within the rule. The more abstract a pointcut is, the less duplication it presents and the less fragile it is. 

%Even if we could drop the duplication out completely, it would have damaged the readability
The most abstract pointcut does not introduce any duplication and is not fragile at all. Unfortunately, it is also of no use, since it matches any possible join point. This means that eliminating the duplication completely from patterns is not technically possible. Fortunately, we do not want this: if no information about a grammar is present in an aspect, this makes it much less readable because the reader has no clue about how the annotations are connected to the grammar. Thus, there is a trade-off between the readability and duplication in grammatical aspects and a developer should keep pointcuts as abstract as it is possible without \bad{damaging} readability.

To summarize, our approach allows one to keep a context-free grammar completely clean by moving annotations to aspects and to avoid any unnecessary duplication by using abstract pointcuts. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}\label{Related}

Several attribute grammar (AG) systems, namely \tool{JastAdd} \cite{JastAdd}, \tool{Silver} \cite{Silver} and \tool{LISA} \cite{LISA}, successfully use aspects to attach attribute evaluation productions to context-free grammar rules.
AGs are a generic language for specifying computations on ASTs. They are well-suited for tasks such as specifying translators in general, which require a lot of expressive power. But the existence of more problem-oriented tools such as \tool{Pretzel} \cite{Pretzel} suggests that the generic formalism of AGs may not be the perfect tool for problems like generating pretty-printers.
In fact, to specify a pretty-printer with AGs one has to produce a lot of boilerplate code for converting an AST into a string in concrete syntax.
As we have shown in \secref{Example}, \Grammatic{} facilitates creation of such problem-oriented tools providing the syntactical means (grammatical aspects) to avoid tangled grammars and unnecessary duplication.

The \tool{MPS} \cite{MPS} project (which lies outside the domain of textual languages since the editors in \tool{MPS} work directly on ASTs) implements the approach which is very close to ours. It uses aspects attached to the \emph{concept language} (which describes abstract syntax of \tool{MPS} languages) to provide input data to generators. The implementation of aspects in \tool{MPS} is very different from the one in \Grammatic{}: it does not use pointcuts and performs all the checking while the aspects are created.

There is another approach to the problems we address: parser generators such as \tool{SableCC} \cite{SableCC} and \tool{ANTLR} \cite{ANTLR} can work on annotation-free grammars and produce parsers that build ASTs automatically. In this way the problems induced by using annotations are avoided. The disadvantage of this approach is that the ASTs must be processed manually in a general-purpose programming language, which makes the development process less formal and thus more error-prone.

% http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.8868 --- pretty-printer generator
% pretzel pretty-printer generator
%
% vim highlighter http://www.vim.org/scripts/script.php?script_id=274
%
% GLF in NetBeans http://wiki.netbeans.org/GLFTutorial#Tutorial_.28GLF.29
%
% MyDefragScript syntax highlighting generator http://www.mydefrag.com/forum/index.php?topic=1981.0
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{Conclusion}

Annotated grammars are widely used to specify inputs for various generators which produce language support tools.
In this paper we have addressed the problems of tangling and duplication in annotated grammars. Both problems affect maintainability of the grammars: tangled grammars take more effort to understand, and duplication, besides the need to make every change twice as the language evolves, may lead to inconsistent changes in different copies of the same grammar.
We have introduced \emph{grammatical aspects}, and showed how they may be used to cope with these problems by separating context-free grammars from annotations. 

The primary contributions of this paper are:
\begin{itemize} 
	\item Formal definition of grammatical aspects and their semantics.
	\item A tool named \Grammatic{} which provides languages for specifying grammatical pointcuts, advice and aspects, and implements the semantics of matching and aspect application.
\end{itemize}

We have demonstrated how \Grammatic{} may be used to generate a syntax highlighter and a pretty-printer by applying two different aspects to the same grammar. We have shown that grammatical aspects help to ``untangle'' grammars from annotations, and eliminate the unnecessary duplication. The possible negative impact of remaining duplication (necessary to keep the aspects readable) can be addressed in two ways:
	(i) \emph{abstract patterns} reduce the amount of changes in aspects per change in the grammar, and
	(ii) \emph{multiplicities} help to detect inconsistencies at generation time.

One possible way to continue this work is to support grammar adaptation techniques \cite{Laemmel} in \Grammatic{} to facilitate rephrasing of syntax definitions (e.g.,~left factoring or encoding priorities of binary operations) to satisfy requirements of particular parsing algorithms.

Another possible direction is to generalize the presented approach to support not only grammars, but also other types of declarative languages used as inputs for generators, such as UML or XSD.

\bibliographystyle{plain}
\bibliography{grammatic_ldta_10}

%%%%%%%%%%% The bibliography starts:
%\begin{thebibliography}{99}
%\bibitem{r1}

%\end{thebibliography}
\end{document}
